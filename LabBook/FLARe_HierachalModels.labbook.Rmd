---
title: "Hierachal computational modelling - FLARe"

output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: true
    number_sections: true
    highlight: monochrome
    theme: cerulean
    code_folding: show
     
  html_notebook:
    theme: cerulean
    toc: yes
   
---

# Introduction {.tabset}

Lab book for analyses using hierachal computational modelling to identify paramters that define the best model of learning as it applies to fear conditioning acquisition and extinction using FLARe fear conditioning data. 
Long abstract, justification and analysis plan found in prelim manuscript [here]([https://docs.google.com/document/d/1JhVCf0jlXFwXYQ2kjS3fpl7mYexDcULn7L1ZgJ6Nolw/edit?usp=sharing])

In short:

## Aims    
     
1.  Identify model of learning based on a priori hypotheses that best fits the trajectories of fear relevant learning in our FLARe dataset
      + Use all first week data from Validation, app TRT, lab TRT, Pilot, Headphones (n = 223 after exclusions)
      + Include Acquisition, extinction (trajectories representing fear learning and treatment)
      + Identify parameters that define these trajectories
          + e.g. Learnign rate, plateau, first ambiguous trial etc.
          
2.  Cross validate best fitting model in TEDS data

3.  Are these parameters associated with other emasures of indsividual differences in our datasets?
      + Personality (Neuroticism)
      + Current anxiety symptoms (GAD-7) - equivalent of baseline symptoms (Chris + Meg analyses)
      + Lifetime / trait anxiety (STAI / ASI - FLARe analyses)
      + Current depression symptoms (PHQ-9) -  equivalent of baseline symptoms (Chris + Meg analyses)
      + Interpretation biases (IUS, ASSIQ - FLARe analyses)
      + SES (Meg IAPT: benefits, employment etc) 
      + Gender (Meg analyses)
      + Emotion regulation profile (potentially LCA based?)


## Impact and relevance

```
Evidence from both human (Richter et al., 2012) and rodent (Galatzer-Levy, Bonanno, Bush, & LeDoux, 2013) studies suggest that trajectories of how we learn and extinguish fear differ between individuals. Different trajectories of fear and extinction have also been found using fear conditioning studies (e.g. Duits et al., 2016), a good model for the learning of, and treatment for, fear and anxiety disorders. It is likely that these trajectories of fear extinction might predict outcomes in exposure-based cognitive behavioural therapy (Kindt, 2014). 
 
Identifying parameters that predict individual trajectories of fear learning and extinction will enable us to harness fear conditioning data more effectively to aid in understanding mechanisms underlying the development of and treatment for anxiety disorders. With more accurate models of these processes, the potential to use fear conditioning paradigms to predict those most at risk of developing an anxiety disorder, and those who might respond best to exposure-based treatments, greatly improves.
```

## Useful references

[Sutton and Barto Reinforcement Learning](http://incompleteideas.net/book/RLbook2018.pdf) - Textbook on reinforcement learning   
[Anxiety promotes memory for mood-congruent faces but does not alter loss aversion (Charpentier...Robinson, 2015)](https://www.nature.com/articles/srep24746.pdf) - Good example of a sensitivity learning parameter    
[Hypotheses About the Relationship of Cognition With Psychopathology Should be Tested by Embedding Them Into Empirical Priors (Moutoussist et al., 2018)](https://www.frontiersin.org/articles/10.3389/fpsyg.2018.02504/full) - Including variables of interest (e.g. anxiety) in the model    



## Analysis plan 

1.  Define set of a priori models moving from simple to more complex   
      + Some paramters to include: 
        + Rate of learning (sometimes with punishment reinforcement)
        + Sensitivity to punishment
        + Pre-existing anxiety
        + SES? Gender?    
        

        
2.  Run each model and compare fit in FLARe pre TEDS data
      + Use Log likelihood and BIC etc.    
      
      
3.  Select best fitting model   


4.  Extract individual data for learning parameters from this model and see what factors best predict it
      + Anxiety (if anxiety isnt best as part of the model)
      + Interpretation biases
      + Tolerance of uncertanty
      + Cognitive emotional control
      + emotional attentional control 
      + SES?
      + Gender?    
      

4.  Run all models again in FLARe TEDS
      + Decide if the same model best fits the data again.
      + See if we get similar results from the parameter prediction   
      
    


Will use a combination of `R.Version(3.5.1)`, `RStan (Version 2.18.2, GitRev: 2e1f913d3ca3)` and `hBayesDM package in R (3.5.1)` [Ahn, W.-Y., Haines, N., & Zhang, L. (2017). Revealing neuro-computational mechanisms of reinforcement learning and decision-making with the hBayesDM package. Computational Psychiatry, 1, 24-57.](https://doi.org/10.1162/CPSY_a_00), which uses RStan

# Analyses {.tabset}

## Preliminary 

### Set up

These use Alex Pikes RStan script with minor modification to make it punishment only to see if it runs. Testing that the approach works with the current data set up etc.  

The settings for the script are below, including stan chain paramters and directory set up.

```{r, echo=F,results=F}

#clears environment
rm(list=ls())

#testing is TRUE means runs with less of everything for speed
testing=TRUE

# directories
workingdir='/Users/kirstin/Dropbox/SGDP/FLARe/FLARe_MASTER/Projects/Hierachal_modelling/Modelling'
scriptdir='/Users/kirstin/Dropbox/SGDP/FLARe/FLARe_MASTER/Projects/Hierachal_modelling/Scripts'
datadir='/Users/kirstin/Dropbox/SGDP/FLARe/FLARe_MASTER/Projects/LatentGrowth/Datasets/'

# stan parameters

chain_iter=5000 # number of iterations for each chain inc. warmup (half)
if (testing==TRUE) chain_iter=500
chain_n=4 #4 chains
if (testing==TRUE) chain_n=1

```

This loads the libraries and source files needed to run this script, and sets up RStan

```{r, echo = F,results='hide',message=F}

# libraries and source files 
library('MASS')
library('boot')
library('dplyr')
library('reshape')
library('tidyr')
library('rstan') 
library('loo')    # this is model comparison package. helps extract loglikelihood too.
library('data.table')

#options for RSTAN
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
Sys.setenv(LOCAL_CPPFLAGS = '-march=native')
Sys.getenv('LOCAL_CPPFLAGS') #should say '-march=native'

#functions (if and when relevant and added)
# source('/Users/kirstin/Dropbox/SGDP/Function_library/<<function script name>>')
source('/Users/kirstin/Dropbox/SGDP/Function_library/not_in.R') # Not in %!in% function

```

### Try RStan

See if the basic punishment only learning model for the CS+ and CS- works with the FLARe master data

#### Run the 8schools check

From the [rstan github](https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started)

This is to check that all is compiling and working and to give and idea of data format etc.



#### Adjust dataframe

load in the week 1 app and lab data for FLARe pilot, TRT and headphones studies. Make it long form.

Try with acquisition data first. This is formatted with no column names, with no missing data.

Derive the n parameter for both files and check these match

```{r}

stanname='punish_only.stan'
minus_name <- 'bayes_acq_minus.csv'
plus_name <- "bayes_acq_plus.csv"

stanfile <- file.path(scriptdir, stanname)
minusfile <- file.path(datadir,minus_name)
plusfile <- file.path(datadir,plus_name)


minus <- fread(minusfile,data.table=F)
plus <-fread(plusfile,data.table=F)

nacqm <- dim(minus)[1]
nacqp <- dim(plus)[1]


## check that these match and create nsub variable for RStan

if (nacqm == nacqp) {
  print('subject number match')
  nsub <- nacqm
  
  print(paste('nsub set to',nsub,sep=" "))
} else {
  print('WARNING: subject number does not match. Check master dataset')
}

# check the file format is ok

minus[1:2,]
plus[1:2,]

# create the n trials variable for RStan

ntrials <- 12

```

The expectancy rating datasets look like they are formatted fine and ntrials and nsub variables should exist. 

##### Create scream data

Need to go back to stage zero and keep scream yes/no as a variable. For now to see if this runs create simulated version for the CS+. CS- will remain the same.

```{r}

screamMinus <- matrix(0L,nrow=nsub, ncol=ntrials)

# Initialise plus dataset in the same way, but make the first trial 1 for everyone, then add 8 additional random 1's per person. Do this in four random patterns to mimic the real data

sc1 <- c(1,1,0,1,0,0,1,1,1,1,1)
sc2 <- c(0,1,1,1,0,0,1,1,1,1,1)
sc3 <- c(1,1,1,0,1,0,1,0,1,1,1)
sc4 <- c(1,0,1,1,0,0,1,1,1,1,1)


screamPlus <- matrix(0L,nrow=nsub, ncol=ntrials)

screamPlus[,1] <- 1


# for (n in 1:dim(screamPlus)[1]) {
#   print(n)
#   screamPlus[n,2:12] <- sample(patts,1,replace=T)
# }


for (n in 1:dim(screamPlus)[1]) {
  
  a <- sample(c(1,4),1)
  
  if (a == 1) {
    screamPlus[n,2:12] <- sc1
  } else if (a == 2) {
    screamPlus[n,2:12] <- sc2
  } else if (a == 3){
    screamPlus[n,2:12] <- sc3
  } else {
    screamPlus[n,2:12] <- sc4
  }
}

```


##### make rating data binary


for now to see if stan runs using bernoulli-logit function make binary resposnes from expectancy i.e. >=4.5 ==1, <= 4.5 ==0. 



```{r}

binarise <- function(x) {
  ifelse(x >= 4.5,1,0)
}

```

```{r}


minus <- data.frame(apply(minus,2,function(x) binarise(x)))

plus <- data.frame(apply(plus,2,function(x) binarise(x)))

```



#### Set up procedure to create and sync models.

This directs to my local machine here ***/Users/kirstin/Dropbox/SGDP/FLARe/FLARe_MASTER/Projects/Hierachal_modelling/Scripts*** and is remotely linked to the github [repository here](https://github.com/klpurves/FLARe_Bayesian_hierarchical).  

##### Make sure the most up to date stan file is in the remote repo


```{bash}

git pull Bayes_modelling
   
```

##### check existing paramters

Unhash this if you want to check what the model looks like within the notebook.

```{bash}
stanname="punish_only.stan"
scriptdir="/Users/kirstin/Dropbox/SGDP/FLARe/FLARe_MASTER/Projects/Hierachal_modelling/Scripts"

#cat $scriptdir/$stanname

```


##### Make any changes

use echo to push these to the new file if you want to make changes from here. 

```{bash} 

## initialise bash directory and filename

stanname="punish_only.stan"
scriptdir="/Users/kirstin/Dropbox/SGDP/FLARe/FLARe_MASTER/Projects/Hierachal_modelling/Scripts"


#echo "<any changes here>" > $scriptdir/$stanname

```

##### Any push the updates to github

Unhash the series below if you made any changes.



```{bash}

## initialise bash directory and filename
stanname="punish_only.stan"
scriptdir="/Users/kirstin/Dropbox/SGDP/FLARe/FLARe_MASTER/Projects/Hierachal_modelling/Scripts"


## stage
#git add $scriptdir/$stanname


## push 

#git push Bayes_modelling 


```

#### Now try run stan



```{r}
flare_data<-list(ntrials=ntrials,nsub=nsub,includeTrial = rep(1,ntrials), screamPlus=t(screamPlus),screamMinus=t(screamMinus),
                 ratingPlus=t(plus),ratingMinus=t(minus))

flare_fit <- stan(file = stanfile, data = flare_data, iter=chain_iter, chains = chain_n) #add working dir?

save(flare_fit, file=file.path(datadir,'flare_fit_test'))

traceplot(flare_fit,'lp__')

# extract fit data
summary_flare<- summary(flare_fit)

# extract model summary data

flare_loglike<- extract_log_lik(flare_fit, parameter_name = "loglik", merge_chains = TRUE)



```

view the fit information

```{r}

summary_flare

```
extract the loglikelihood using loo

```{r}

loo(flare_loglike)

```





